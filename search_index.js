var documenterSearchIndex = {"docs":
[{"location":"content/intro/#Why-Should-I-Care-about-Graphics?","page":"Introduction","title":"Why Should I Care about Graphics?","text":"","category":"section"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"During my PhD, I got this question a lot. To be honest, it's a good question. If you are a scientist that studies the motion of galaxies (or some similar problem), why would you care about the latest animation from PIXAR or DreamWorks? Well, let's talk about that.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"As a reminder, GPU stands for Graphics Processing Unit. Historically, its purpose has been to do graphics. Games. Visualizations. You know. Graphics.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"These workflows typically require a lot of simple operations. For example, we might need to move a bunch of points from one set of locations to another. Or color a bunch pixels red (or any other color). Or to track a bunch of rays of light bouncing around a scene.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"It's not particularly difficult to whip up some code in Python, C, or Julia to solve these problems for us. The trouble comes from the fact that these operations often need to be done a lot – thousands or millions of times. We also usually need the results immediately – like within one sixtieth of a second. When there are a large number of operations and a really short time limit, it suddenly makes sense to offload computation to a separate device that is built for that kind of work.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"That's what the GPU is. A separate device that is built to solve a lot of simple operations at the same time.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"I need to stop and expand upon the three separate claims made in the previous statement.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"The GPU is a separate device: This means that we often need a special protocol to use it from our programming language of choice, and we need to think about how to transfer data to and from the GPU.\nThe GPU ... is built to solve ... simple operations: This means that certain workflows are not well-suited for the GPU. We'll give more examples of these later in the book.\nThe GPU ... is built to solve a lot of ... operations at the same time: This means that we need to actively think about what each computational core of the GPU is doing in parallel.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"I have often said that research in computational science mirrors research in computer graphics. Computer graphics researchers generally work on hardware and software tooling for GPUs – small, parallel devices that can fit on modern motherboards. Computational scientists generally work on hardware and software tooling for supercomputers – large, parallel networks of computers strung together to solve difficult problems. In a sense, both groups have been attempting to do the same thing: break up complex tasks into simpler ones so they make better use of parallel hardware. Eventually, the two forces met and General Purpose GPU (GPGPU) computing was born. Nowadays, the fastest supercomputers in the world use GPUs for computation. It's pretty clear that the GPU does more than \"just graphics.\"","category":"page"},{"location":"content/intro/#But-What-If-I-Actually-Care-About-Graphics?","page":"Introduction","title":"But What If I Actually Care About Graphics?","text":"","category":"section"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"Another great question!","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"This book is specifically written for students who want to use their GPU for more general applications (like large-scale simulations). It is a little unfortunate that the programming interfaces used for graphics are typically quite different than those used for computing. If you are interested in building a game or rendering engine, it might be best to think of this book as a way to satiate some idle curiosity that might be lingering in the back of your head. It's all good to know, but it's ok to read it for fun instead of rigor.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"That said, there are still a number of good reasons to keep reading:","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"It is entirely possible to use the lessons learned from this book to do \"software rendering,\" which can be more flexible than traditional graphics workflows.\nWe'll be discussing several graphical applications that are well-suited for computational workflows, such as ray marching and splatting.\nEven within traditional graphics workflows, there are certain applications that use \"compute shaders\" for various reasons (volume rendering and particle systems both come to mind). Compute shaders are almost identical to the functions we will be writing in this book.\nThis book should give you some key intuition about how and why the GPU works the way it does, which could be quite valuable for performance engineering down the road.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"But there is a larger question here. Why is there such a big difference between interfaces for graphics and interfaces for computation? After all, we are all programming for the same device, right? At the end of the day, it's all GPU.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"Well, this brings up something that I really have to say before continuing further.  An unfortunate truth about GPU computing in 2025 that all students must be aware of before proceeding further. No matter what language, interface, or method you decide to use for GPU programming, they all share one thing in common: jank.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"Simply put, GPU interfaces are way, way less polished than you might expect when transitioning from \"traditional\" CPU programming. Some of this is because GPUs are inherently parallel devices, while CPU code is often written without parallelism in mind. But I would argue that majority of programmers struggling with GPU programming in 2025 are not necessarily struggling with concepts, but are instead limited by the software used to implement those concepts.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"I think now is a good time to talk about the GPU ecosystem as a whole, and in particular...","category":"page"},{"location":"content/intro/#The-Big-Green-Elephant-in-the-Room","page":"Introduction","title":"The Big Green Elephant in the Room","text":"","category":"section"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"It is often very difficult to recommend a GPU language or programming interface. In fact, in 202X, there is no single language that I can truly recommend. For those who know GPU computing, you might be raising your eyebrow at the previous sentence. After all, there certainly is a single programming interface that has dominated the GPGPU space for literal decades. It has so much market share, that the company in charge of its design is now one of the most profitable companies in the history of our planet. Yes, I am talking about NVIDIA and their programming interface CUDA.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"The problem is that CUDA only works on NVIDIA cards, so if you write CUDA code, you must necessarily also have NVIDIA hardware available. That's not always the case. A bunch of people choose AMD hardware instead of NVIDIA. Many people are running macs. Some are just using their phone as a computer.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"The fact is that we have no control over the hardware our users might have. More than that, every hardware vendor provides their own, distinct programming interface that will almost certainly fail to cooperate with other interfaces from different vendors. Simply put, CUDA works for NVIDIA hardware. ROCm is for AMD. Metal is for Apple Silicon (Macs). None of these languages talk to each other. So what do we do? Well, the \"obvious\" solution would be to support all possible hardware, but this means that any time we need to make a minor change to our code, we also need to mirror that change to all of the other programming interfaces for all of the different hardware vendors. What might have been a single afternoon of work might suddenly turn into a week of testing and still failing to get everything right.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"But there must be a better way, right?","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"Kinda. Cross-platform GPU interfaces allow you to write functions that run at essentially the same speed as vendor-specific programming interfaces (like CUDA), but those functions are not limited to specific hardware. This means that the same code can run on AMD, Intel, Apple Silicon, and NVIDIA hardware. In fact, many cross-platform interfaces allow for that same code to run in parallel on the CPU as well. In particular, the Open Compute Language (OpenCL) can even run on many cell phones and Field Programmable Gate Arrays (FPGAs), which are separate devices used in completely different types of problems for performance reasons.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"So what's the catch?  Why doesn't everyone use cross-platform interfaces? Well, it's hard to overstate how incredibly dominant CUDA has been in the GPGPU space for so many years. Sure, you could write your code in a cross-platform way, but why would you? You would be taking a small performance hit (something like 10%) and it would take an extra week to write your code. Plus, all of the common GPU programming guides are in CUDA. Time is money, and it takes time to learn. From a business perspective, it's better to just pay an extra hundred dollars on an NVIDIA card and save yourself (and your employees) the hassle.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"To reiterate, almost all non-CUDA interfaces have the same drawback: they are not CUDA. This means that there is less documentation available. The code will be buggier and with less developer support. The experience simply won't be as smooth as CUDA. In a world where everyone is trying to get the absolute best performance possible as quickly as possible, these are huge issues.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"Long story short, it's impossible to talk about GPU computing without acknowledging the big green elephant in the room: CUDA.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"Still, I have no idea who is reading this book or what devices they have available. I can't count on everyone having an NVIDIA GPU to use, and for that reason alone I do not feel that CUDA is suitable for this work. That said, I am certain everyone will have some device at their disposal that can run GPU code, so I will focus on languages (or rather a single language) that I am confident the majority of my audience can use.","category":"page"},{"location":"content/intro/#If-not-CUDA,-then-What?","page":"Introduction","title":"If not CUDA, then What?","text":"","category":"section"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"After a lot of thought, I settled on using Julia and the KernelAbstractions(.jl) package for this book. There are benefits and drawbacks of this choice, which I could ramble about for hours, but in short, Julia provides:","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"A flexible software ecosystem that works on any GPU vendor (AMD, NVIDIA, Apple Silicon, Intel).\nThe ability to write code that can execute both on the GPU and in parallel on the CPU at the same time.\nA way to execute GPU code without writing GPU-specific functions or \"kernels.\"\nA straightforward package management approach so users don't have to think about library installation.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"There are a few other benefits, but this specific combination of useful features cannot be found anywhere else.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"To be clear, the Open Compute Language (OpenCL) also shares many of these advantages and even has a few distinct benefits over Julia as well. Unfortunately, OpenCL is a little less straightforward to use. The way I see it, this book is about teaching GPU concepts, and the JuliaGPU ecosystem allows me to quickly do just that. If I were to write this book with OpenCL (or even CUDA), I would need to spend a significant amount of time explaining syntax and odd quirks to C (or god-forbid C++), that I just don't want to deal with. Again, I am actively encouraging you to rewrite this entire book in the language of your choice. For me, I'm planning to stick to Julia, but there are a few limitations to this choice that I will mention throughout this book.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"Also, to be completely transparent, I have contributed to the GPU ecosystem in Julia in several ways, including the KernelAbstractions package we will be using for this work. This could be seen as a net benefit. After all, how often do you get to read a book from a developer of the tools you will be using? On the other hand, I need to acknowledge my biases and let you (the reader) know that several of my opinions might be a little too favorable towards Julia and that your day-to-day experience with the language might fall a little short depending on your familiarity.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"On the other (other) hand, I really do try to be as objective as possible when talking about projects I am passionate about. There's nothing worse than being sold a tool you can't actually use in practice. That's why I am absolutely encouraging you to take the code in this book and rewrite it into the language of your choice.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"Alright. That's enough rambling. We'll be doing a lot more of it later. Now, let's talk about the...","category":"page"},{"location":"content/intro/#General-Structure-and-Limitations-of-this-Book","page":"Introduction","title":"General Structure and Limitations of this Book","text":"","category":"section"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"As much as I hate to say it, our time on this Earth is limited. It goes without saying that there are things I can cover, and things I can't.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"My ultimate goal with this book is to provide a \"quick-start\" guide for those wanting to learn how to get started with GPU computing. That means that I intend to cover a number of core ideas and concepts that are necessary to consider when trying to achieve good performance on the GPU as well as key applications that I find interesting and useful for a diverse background of research fields. To do this, I have (more or less) structured this book around interesting, key examples intended to demonstrate the lessons I would like to teach. There will certainly be areas I miss, but I hope the areas I get to will be generally useful for the most possible people.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"note: Reviewer Notice\nI'll be coming back to this section later with a full overview once the chapters are more-or-less finalized","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"It is also important to discuss several known limitations of this book:","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"We will not be surveying different languages. This book is primarily intended to teach concepts over code. Once you master everything here, it should be relatively straightforward to translate it to whatever language you need for your final application. With that said, I will be highlighting languages and their differences as they become relevant in their respective sections.\nWe will not be discussing specialized hardware that certain vendors add to their GPUs. This means no discussion of (for example) hardware rasterization, raytracing (except in software), or tensor cores.\nWe will not be analyzing performance via NVIDIA-specific tooling like NSight compute. I simply don't think it is fair to have a chapter on performance analysis that only works for NVIDIA devices.","category":"page"},{"location":"content/intro/","page":"Introduction","title":"Introduction","text":"With all that said, I think it's time to finally start coding! In the next chapter, I'll be introducing several core abstractions programmers use when writing GPU code and getting you started in running that code on your hardware (whatever that might be).","category":"page"},{"location":"content/splatting/#The-Jank","page":"-","title":"The Jank","text":"","category":"section"},{"location":"content/splatting/","page":"-","title":"-","text":"Yeah. I'm going to come out and say it. No matter what language or interface you use for GPU programming in 2024, you will probably find yourself at least a little disappointed. They all feel a little rough, lacking the polish that programmers are used to nowadays. It is downright impossible to describe this problem fully. GPU functions look odd when compared to their CPU counterparts. Also, many common programming techniques simply don't work on the GPU. Way back.","category":"page"},{"location":"content/splatting/","page":"-","title":"-","text":"In general, a \"language\" is a method of communication between two (or more) individuals. A \"programming language\" is a method to communicate with a computer. Programming languages typically require a translation (compilation) step to transform the user-submitted code to something that the computer can understand.","category":"page"},{"location":"content/splatting/","page":"-","title":"-","text":"Nowadays, many languages will have multiple compilation steps, and will first lower the user code into a Lower-Level Intermediate Representation (LLIR) before then compiling down to machine code. The core advantage here is that the lowered code can then be compiled to different hardware. Simply put, the final set of instructions for AMD and Intel machines might be different, but the intermediate representation can be shared.","category":"page"},{"location":"content/splatting/","page":"-","title":"-","text":"Many languages (Julia, Rust, and even C sometimes) will compile down to the same intermediate representation known as LLVM (which stands for Lower-Level Virtual Machine). This means that as long as the conversion from Julia to LLVM is done well, it should be (roughly) the same speed as C.","category":"page"},{"location":"content/splatting/","page":"-","title":"-","text":"In a sense, GPU programming is not as straightforward. Until now, I have been careful not to call the GPU protocols \"languages,\" because they usually take regular languages (C, Python, Julia, Rust, etc) and extend the functionality to run on a GPU. For this reason, I have instead called them \"interfaces,\" and you will regularly see them called Application Programming Interfaces (APIs) when people talk about them in the \"real\" world. It is important to note that because the GPU interfaces target the GPU (and not the CPU), the all boil down to a different intermediate representation than for the CPU.","category":"page"},{"location":"content/splatting/","page":"-","title":"-","text":"That said, some of the GPU interfaces will still compile down to something like LLVM that has been modified for the GPU (NVPTX for CUDA, for example). Others compile down to another intermediate representation entirely. For example, OpenCL (the Open Compute Language) and Vulkan (a graphics interface) both compile down to something called SPIRV.","category":"page"},{"location":"content/splatting/","page":"-","title":"-","text":"Now, I hear what you are saying, \"That's great! We've got ourselves an open standard (SPIRV) that has unified both graphics and compute! Isn't that a core issue we already talked about in this chapter? Surely all the other interfaces will rally behind it, right?\"","category":"page"},{"location":"content/splatting/","page":"-","title":"-","text":"Ok. Good question. It's impossible to answer without diving (at least a little bit) into the weeds.","category":"page"},{"location":"content/splatting/","page":"-","title":"-","text":"Simply put, reality is not that simple. The problem with SPIRV is that it's a bit too broad. Unlike LLVM, which is the same no matter what language is using it (Julia, Rust, C), SPIRV has two distinctly different implementations for graphics and compute. That is to say that the SPIRV implementation for OpenCL (a compute language) is not the same as the SPIRV implementation for Vulkan (a graphics interface).","category":"page"},{"location":"content/splatting/","page":"-","title":"-","text":"This is honestly maddening! What this means is that you cannot use compute functions written in OpenCL in a graphics language like Vulkan even though they both use SPIRV! Though it is entirely possible to work on the LLVM level and create applications that work across multiple CPU languages, the same is not true for GPU languages – not only because not all compute languages boil down to SPIRV, but SPIRV is not always the right SPIRV for specific uses.","category":"page"},{"location":"content/splatting/","page":"-","title":"-","text":"This little rant has a valuable piece of information hidden just below the surface. The state of GPU computing in 2024 is largely unpolished, and while reading this book, you might find yourself frustrated. It might feel like the software is holding you back from unleashing your true potential. In some ways, it is. Some seemingly simple questions might lead you down complicated paths and suddenly, you have spent months worrying about subtle nuances in different compilation strategies that make you feel like your entire codebase is held together by unchewed bubble gum.","category":"page"},{"location":"content/splatting/","page":"-","title":"-","text":"When such problems arise, it's important to breathe and reframe your question. Sometimes it will take time. Sometimes, there is no solution, and you will have to shrug your shoulders and work on something else for a while. But in most cases, there will be a solution to your problem. You just might need to get a little creative.","category":"page"},{"location":"content/splatting/","page":"-","title":"-","text":"It is important to keep in mind that CPU languages have had years (decades) to figure out how to create fast, efficient CPU code. GPU languages, on the other hand, are relatively new and have yet to stabilize on a lower-level scheme that works across all languages. No matter who you ask, the GPU ecosystem (at large) is incredibly messy right now. I really hope that this book helps clarify some of that mess.","category":"page"},{"location":"content/julia/","page":"Julia: A Chainsaw of a Language","title":"Julia: A Chainsaw of a Language","text":"note: Reviewers Notice\nI have made a potentially fatal \"executive decision\" when writing this book. Simply put, I don't want a full chapter on Julia as a language. Rather, I will sprinkle in topics as they become relevant to the greater discussion on GPU computing. I am not entirely convinced this is the right approach, so if you think a full chapter on Julia would be worthwhile, let me know!On that note, I have been intending to write another book, Intro.jl, a simple guide to introduce new programmers to Julia. It could act as a sister-guide to this one. GPU questions would be answered in this book. Julia questions would be answered in the other one. If you put them together and someone with no programming experience could be up and running with GPU computing simply by completing all the exercises.That said, there are other people who could probably write an introduction to Julia book better than I could, so I am not convinced I should write Intro.jl either. Let me know if you think I am going too quickly through the Julia discussion in this book. If so, then Intro.jl becomes more worthwhile as a standalone book. We can then \"hit the ground running\" with GPU computing here.","category":"page"},{"location":"content/julia/#Julia:-A-Chainsaw-of-a-Language","page":"Julia: A Chainsaw of a Language","title":"Julia: A Chainsaw of a Language","text":"","category":"section"},{"location":"content/julia/","page":"Julia: A Chainsaw of a Language","title":"Julia: A Chainsaw of a Language","text":"In casual conversation, the word \"simple\" is often used interchangeably with the phrase \"easy to use\"; however, when it comes to tools that we use on a daily basis, the two concepts might actually be opposite of each other. For example, let's say we are asked to cut down a forest and are given the choice of two tools: either a chainsaw or an axe [1] Clearly, the axe is simpler to use. We just need to pick it up, point the bladed edge towards a tree, and chop. The chainsaw, on the other hand, requires a bit more knowledge on how to power it, keep the chains lubricated, and ensure the safety of ourselves and everyone around us. Even with this added complexity, I think that we can all agree that the chainsaw is a much better tool for this job. In short: for this problem, the axe is simpler, but the chainsaw is easier to use.","category":"page"},{"location":"content/julia/","page":"Julia: A Chainsaw of a Language","title":"Julia: A Chainsaw of a Language","text":"[1]: For the record, I am not advocating that you actually cut down a forest. This discussion is purely hypothetical.","category":"page"},{"location":"content/julia/","page":"Julia: A Chainsaw of a Language","title":"Julia: A Chainsaw of a Language","text":"It's important to make this distinction with software as well. Often times, the easiest software to use is also the most complicated under-the-hood. Simultaneously, the simplest software is the hardest to use in practice. Take C for example. It is a relatively simple programming language – so simple, in fact, that it can be easily called from most other high-level languages. It's also blazingly fast – usually the fastest language available for most tasks. So why not just code directly in C? Because it's too simple. It's missing a lot of the features modern-day users want: plotting, dynamic recompilation, safe memory management, and so on.","category":"page"},{"location":"content/julia/","page":"Julia: A Chainsaw of a Language","title":"Julia: A Chainsaw of a Language","text":"How is this all related to Julia? Well, Julia is the easiest language I have ever used, which means that it often feels incredibly complicated under-the-hood.","category":"page"},{"location":"content/julia/","page":"Julia: A Chainsaw of a Language","title":"Julia: A Chainsaw of a Language","text":"It is a chainsaw, and it's important to keep that in mind throughout the rest of this book.","category":"page"},{"location":"content/julia/#Installing-Julia","page":"Julia: A Chainsaw of a Language","title":"Installing Julia","text":"","category":"section"},{"location":"content/about_me/#About-the-Author","page":"About the Author","title":"About the Author","text":"","category":"section"},{"location":"content/about_me/","page":"About the Author","title":"About the Author","text":"I am Dr. James Schloss. I received my PhD in 2019 from the Okinawa Institute of Science and Technology Graduate University (OIST). While there, I studied quantum systems by simulating them with my Graphics Processing Unit (GPU). After that, I have been working off and on in the Julia Lab at MIT (a very prominent research arm of the Julia programming language), where I have worked on various scientific computing projects such as climate and molecular simulations. All of these projects have been done on the GPU. Though I would not consider myself to be a core developer of the JuliaGPU ecosystem, I have contributed to several packages, including KernelAbstractions(.jl), the GPU interface we are using for this work.","category":"page"},{"location":"content/about_me/","page":"About the Author","title":"About the Author","text":"I also run the (relatively) popular youtube channel and twitch stream Leios Labs, where we have been developing a book for uncommon algorithms known as the Arcane Algorithm Archive. Some of the chapters in this book were inspired by that work. I have also worked with Grant Sanderson (3Blue1Brown) on several projects, including the Summer of Math Exposition, where we encouraged thousands of online content creators to make more math content online.","category":"page"},{"location":"content/about_me/","page":"About the Author","title":"About the Author","text":"I have always said, \"Your research is only as good as your ability to communicate it.\" The way I see it, there are very few people who have a deep understanding of GPU technology who are also good at communicating that understanding to others.","category":"page"},{"location":"content/about_me/","page":"About the Author","title":"About the Author","text":"This book is my attempt to do both. I might not be the best programmer. I might not be the best communicator. But I am going to try my best to make this work as understandable and enjoyable as possible.","category":"page"},{"location":"content/about_me/#Prominent-Reviewers","page":"About the Author","title":"Prominent Reviewers","text":"","category":"section"},{"location":"content/about_me/","page":"About the Author","title":"About the Author","text":"Any academic work is only as good as the peers who read and critique it. For that reason, I intend to keep a list of \"Prominent Reviewers\" who don't mind putting their name in this section. This should be a list of academics or core community members who have either been asked to review the work due to their expertise or have contributed significantly in the beta reading phase.","category":"page"},{"location":"content/scribblings/#A-note-on-terminology","page":"-","title":"A note on terminology","text":"","category":"section"},{"location":"content/scribblings/","page":"-","title":"-","text":"In order to do this, we need to create terminology for each stage of the process. Keep in mind that each stage of this process also has it's own memory associated with it. Threads have memory. Groups of threads have more memory. GPUs, in general, have memory. Unfortunately, the naming conventions here get a little screwy and depend on which programming interface you are using, so let's write it all down.","category":"page"},{"location":"content/scribblings/","page":"-","title":"-","text":"Hardware concept CUDA terminology KernelAbstractions Terminology\nCore Thread WorkItem\nCore memory  \nGroup of cores Block WorkGroup\nGroup memory Shared Local\nAll cores Grid NDRange\nAll memory Global ","category":"page"},{"location":"content/scribblings/","page":"-","title":"-","text":"To be clear: KernelAbstractions terminology is largely inspired from OpenCL. In this case NDRange means an $N-dimensional range to iterate over. At this stage, it's probably a little confusing and overwhelming, so it might be good to refer back to this table as we have more practical examples.","category":"page"},{"location":"content/scribblings/","page":"-","title":"-","text":"To keep all this straight, it is important to think about this from the thread's perspective. Each thread has access to:","category":"page"},{"location":"content/scribblings/","page":"-","title":"-","text":"A small memory bank to hold local data. This is often called \"local memory.\"\nA slightly larger memory bank to hold data of all threads running at the same time in a \"block\". This is called \"Shared memory.\"\nAn even larger memory bank that holds all available GPU memory. This is called \"Global\" memory.","category":"page"},{"location":"content/scribblings/","page":"-","title":"-","text":"Mention that we can use CUDA.jl or AMDGPU.jl","category":"page"},{"location":"content/reviewers/#Reviewer-Guidelines","page":"Reviewer Guidelines","title":"Reviewer Guidelines","text":"","category":"section"},{"location":"content/reviewers/","page":"Reviewer Guidelines","title":"Reviewer Guidelines","text":"This book is currently in a \"beta reading\" state. That means that I am actively looking for feedback from you, the beta reader. If there is anything funky about the book, please let me know on github or discord. Possible funkiness includes:","category":"page"},{"location":"content/reviewers/","page":"Reviewer Guidelines","title":"Reviewer Guidelines","text":"Typos\nUnclear concepts\nUnnecessary rambling\nImpossible problems","category":"page"},{"location":"content/reviewers/","page":"Reviewer Guidelines","title":"Reviewer Guidelines","text":"... And the like.","category":"page"},{"location":"content/reviewers/","page":"Reviewer Guidelines","title":"Reviewer Guidelines","text":"note: Reviewer Notice\nI will also have a few reviewer notices scattered throughout the book for specific issues that I want more input on.","category":"page"},{"location":"content/reviewers/","page":"Reviewer Guidelines","title":"Reviewer Guidelines","text":"Please keep in mind that I am trying to make GPU computing as easy to understand as possible. It's really hard to do this right. For example, I might over-explain a few concepts that otherwise might be seen as \"trivial\". I might also omit \"important\" jargon that I feel is unnecessary. I am really (overly) relying on you all to gently nudge the book in the right direction and welcome feedback from programmers of all levels.","category":"page"},{"location":"content/reviewers/#Prominent-Reviewers","page":"Reviewer Guidelines","title":"Prominent Reviewers","text":"","category":"section"},{"location":"content/reviewers/","page":"Reviewer Guidelines","title":"Reviewer Guidelines","text":"I feel peer review is an essential part of any academic work. I also feel that it is important to be as transparent as possible about that review process.","category":"page"},{"location":"content/reviewers/","page":"Reviewer Guidelines","title":"Reviewer Guidelines","text":"When the book is finalized, I will ask a few experts that I know to review the work and tell me what they think. With their permission, I will then put their name somewhere in the acknowledgments for the book (probably next to an \"About the Author\" section or something). If you would like to be considered as a \"Prominent Reviewer,\" please...","category":"page"},{"location":"content/reviewers/","page":"Reviewer Guidelines","title":"Reviewer Guidelines","text":"Review a full chapter as if it were an academic paper. I mean, really rip the book to shreds and tell me how big of an idiot I am.\nLet me know your academic background so I can include you.","category":"page"},{"location":"content/reviewers/","page":"Reviewer Guidelines","title":"Reviewer Guidelines","text":"I'll also be keeping an eye out for people who contribute substantially during the review process and reaching out to them to see if they would like to be listed as a \"Prominent Reviewer\" as well.","category":"page"},{"location":"content/reviewers/","page":"Reviewer Guidelines","title":"Reviewer Guidelines","text":"I think that's all for now. Thanks for reading the book and I hope it is helpful in some way!","category":"page"},{"location":"content/abstractions/#All-the-Ways-to-GPU","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"At the end of the day, GPUs are pieces of hardware. Complicated pieces of hardware. In fact, GPUs (and modern CPUs) are so complicated that it would be nearly impossible for an individual to directly write down a set of instructions for the hardware to run. Instead, users write code in some human-readable language like C, Rust, or Julia, which will then be translated to some other language, and then (often times) another language again and again until it becomes the final instruction set that their hardware can execute. This process is known as compilation. As a rule of thumb, the easier it is to read and write in a programming language, the more difficult the compilation process will be.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"At every layer of compilation, we are further simplifying the translation process through software abstractions. Simply put, an abstraction is a metaphorical device used to make a complex task easier to understand. We use abstractions everywhere in programming. Examples include: for and while loops, functions, structures and classes, etc. Basically every common programming device we use is an abstraction of some form. In this chapter, I will introduce many common abstractions that can be used  to perform GPU computation, but let's start at the start.","category":"page"},{"location":"content/abstractions/#Installation","page":"All the Ways to GPU","title":"Installation","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"I think it is important to pause a second before jumping in to the water to remind ourselves of a simple truth: the first step of any project is always the hardest. This also holds true for programming, so if you find yourself a little lost while reading this chapter, that's totally normal. It's ok to put the book down. It's ok to ask for help. The most important thing is that you are steadily making progress towards your goals, whatever they might be.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Now let's begin.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"As mentioned in the introduction, we will be using the Julia programming language for this book, so the first step is to install Julia. It is important to note that this book is intended for those who already have some (at least limited) familiarity with programming. As such, I will keep the installation instructions brief. If you are already used to programming, you probably already have your own preferred development workflows all sorted out and can just google for similar solutions with Julia.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"For most users, installation involves going to the website https://julialang.org/downloads/ [1] and following the instructions. The website provides both binaries for your operating system as well as a command to install a package called juliaup which will allow you to easily update Julia in the future. Linux users (or those with the appropriate software on Windows or Mac) can also install Julia with their package manager. With Julia installed, the next step is decide how to edit code. There are generally two options here:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"With text editors. This means that you will use your text editor of choice (for example: vim, nano, notepad++) and then manage all of your code on your own. You might want to google around for most common options with Julia.\nWith development environments. These are collections of all the things programmers typically need for development packaged into one graphical interface. The most common one for Julia is VSCode, with full installation instructions found here: https://code.visualstudio.com/docs/languages/julia[2].","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Keep in mind that if you are not using Julia and have instead decided to rewrite the code in this book in another language, the installation might be significantly different and potentially more complicated.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"[1]: https://julialang.org/downloads/","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"[2]: https://code.visualstudio.com/docs/languages/julia](https://code.visualstudio.com/docs/languages/julia","category":"page"},{"location":"content/abstractions/#Figuring-out-your-hardware","page":"All the Ways to GPU","title":"Figuring out your hardware","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Now that we have Julia installed, we can start using our GPU! As I discussed in the introduction, the current state of GPU programming is (unfortunately) quite fragmented, so the first step is to identify the hardware on your system. Ideally, you already know this information (because you bought or built your own computer and can look at the specifications), but here's some hints to figure out what you have depending on your operating system:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Windows: Go to the \"Device Manager\" and look under \"Display Adapters\", where you should find the manufacturer of your GPU.\nMac: Go to \"About this Mac\". If it says you are running an \"Apple Mx\" chip, where x is some number, then you can use your Apple Silicon GPU. Otherwise, there might some other GPU shown there.\nLinux: To be honest, there are a bunch of different ways to figure out what hardware you are running, so feel free to google and use your preferred method. My go-to is always lspci | grep \"VGA\", which will tell you what GPUs you have. Other options include lshw -C display or just pasting about:support into the URL for Firefox.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"In the case you have more than one GPU available, feel free to use whichever one you want (or all of them). If you do not have a usable GPU, that is totally ok! You can use your CPU instead for almost everything in this book.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"If you could not figure out whether you have a usable GPU at this stage, that's also totally fine. We can use Julia to figure out which packages will work on your machine. More on that in a moment.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"For now, let's talk about the Julia packages available for your hardware:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Hardware Available Julia Package Julia Array Type\nParallel CPU none Array\nNVIDIA GPU CUDA CuArray\nAMD GPU AMDGPU ROCArray\nIntel GPU oneAPI oneArray\nApple Silicon Metal MtlArray","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Keep in mind that the package names here follow the naming conventions for the traditional software tooling of your hardware. Julia's package for NVIDIA GPUs is CUDA, because it compiles down to the same thing as CUDA (a C language extension for NVIDIA GPU tooling), but does so in Julia. At this point, if you already know your GPU hardware, simply install the relevant package by using the following commands:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia: This will open the Julia shell (called the REPL, which stands for \"Read, Evaluate, Print, and Loop\"). You should see an ASCII Julia logo appear and then a green julia> prompt.\nPress the ] key: This will open up the package manager and change the prompt to something like (@v1.10) pkg>. It will also change the color of the prompt to blue.\nadd GPUBackend: Where GPUBackend is the appropriate package listed in the table above. For example, I have an AMD GPU, so I will add AMDGPU. If I were running an M2 mac, I would add Metal. If I had an NVIDIA GPU, I would add CUDA. Keep in mind that this might take some time because it's installing a lot of GPU driver magic in the background.\nPress backspace: This will leave the package manager\ntype using GPUBackend: Remember that GPUBackend is the package you need for your specific hardware. This will load the package in the Julia REPL. This might take a second as it's compiling everything for the first time.\nGPUBackend.functional(): This will test to make sure the package will work on your machine. It should return true if you have the right hardware available.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"If GPUBackend.functional() returns false, then there is something wrong with the configuration. That is absolutely no problem for the purposes of this text, as you can simply use parallel CPU execution instead of the GPU; however, it might be worth googling around to try to figure out why your GPU is not working (and maybe even create an issue on github for the appropriate package if you feel your GPU should be supported, but isn't).","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Also note that there could have been any number of things that could have gone wrong during this installation process. If the steps above did not work for you, then it is important to search around for a solution. If you can't find a solution, then it's a good idea to reach out to the Julia slack community (there is a #gpu for this kind of thing) or the Julia Discourse. If neither of those resources are helpful, then it might be worth creating an issue for your specific GPU backend.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"tip: But what if I don't know my hardware?\nIn this case, just install all the packages and test them all. Remember, use ] to enter the package manager ((@v1.10) pkg>) and backspace to return to the Julia REPL (julia>):(@v1.10) pkg> add AMDGPU CUDA oneAPI Metal\njulia> using AMDGPU, Metal, oneAPI, CUDA\njulia> AMDGPU.functional()\ntrue\n\njulia> Metal.functional()\nfalse\n\njulia> oneAPI.functional()\nfalse\n\njulia> CUDA.functional()\nfalseHere, I have a working AMD GPU, but none of the other vendors will work. I omitted a few error messages that appeared on my machine when using Metal and using oneAPI as not all users will experience those errors. Both of these packages informed me immediately that my hardware was not supported, so I did not need to run .functional() on those packages (but I did anyway for clarity).After you have found the appropriate package on your machine, feel free to remove the unnecessary ones with:(@v1.10) pkg> rm GPUBackend1 GPUBackend2 GPUBackend3 ...","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"tip: But what if I can't (or don't want to) use the package mode (`]`)?\nYou can actually use the package manager as a package, itself, so...julia> using Pkg\njulia> Pkg.add(\"GPUBackend\")Where GPUBackend comes from the table above. There are a few situations where it just makes more sense to use the Pkg package instead of entering package mode with ].","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"note: Reviewer Notice\nI actually think the using Pkg method is more straightforward for beginners. Should we do that one by default and have a separate tip to explain the ] package management mode?I introduced ] first because (let's be honest) that's how the majority of people interface with the package manager; however, using Pkg is necessary for scripts and CI, so it is also important to know.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"As a final note before continuing, we will be using the notation from the previous table throughout this book. That is to say that I will be using GPUBackend to refer to your specific package (such as AMDGPU on my machine) and ArrayType to refer to the array type from that package (ROCArray on my machine). In the case you \"just want to run the code\" provided here, it might be worth setting these in your Julia REPL and future scripts. For example, on my machine, I might set:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"GPUBackend = AMDGPU\nArrayType = ROCArray","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"If you are using your CPU to emulate GPU execution for this work, then you do not need to set your GPUBackend and instead can remove GPUBackend from all code blocks for them to run. It is up to you how you wish to proceed here and what suits your learning style best. Regardless, we should have all (hopefully) finished installation at this point, so it's time to actually get some work done.","category":"page"},{"location":"content/abstractions/#Your-first-GPU-array","page":"All the Ways to GPU","title":"Your first GPU array","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Alright, we've chosen our appropriate package. Now let's create an array and pass the data to the GPU.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> a = zeros(10, 10)\njulia> b = ArrayType(a)","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"There are a lot of things to talk about. zeros(...) is a Julia method to create an array that is all 0 of a particular size. Here, it's 10 by 10. This command will create an Array object whose memory exists \"on the CPU\". More accurately, the memory will sit on the motherboard RAM, a convenient location for CPU operations. We then need to send that data to the GPU by casting it onto the appropriate array type for our hardware with ArrayType(a). Here, ArrayType is the array type from the table above. For example, those with an AMD GPU would use ROCArray. Those with an NVIDIA GPU would use CuArray. Those with Apple Silicon would use MtlArray.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"It is important to note that the command ArrayType(a) is actually doing two things at once:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Allocating the appropriate space on the GPU\nCopying the data from the CPU to GPU.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"In Julia, these two steps are often coupled, but they don't need to be. For instance, In CUDA (C) a user might use both a cudaMalloc(...) and cudaMemcpy(...). In Julia, we could also avoid the memory transfer and create the array directly on the GPU with:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"b = GPUBackend.zeros(10,10)","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"This would avoid the (relatively) costly communication between the CPU and GPU. In fact, most of the array creation routines (such as rand(...), and ones(...) have similar routines for each backend for simplicity.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"tip: A note about Macs\nIf you are running a Mac, you might not have been able to create your array on the GPU. This is because Metal (the interface used for GPU computation on Apple Silicon) only supports single precision (Float32 and Int32 for example). So to create the necessary array on a mac, specify the type for zeros(...) first, like so:julia> a = zeros(Float32, 10, 10)\njulia> b = MtlArray(a)\n","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Now, depending on your machine, you might have had to wait a few seconds to generate your initial array. What gives? Isn't GPU computing supposed to be fast? Why do we need to wait around all the time?","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Well, one core difference between CPU and GPU programming is in how users think about the code. On the CPU, users typically think about the number of operations each core is performing. Though this is still important with the GPU, calculation speed is often not the biggest bottleneck to GPU performance. Instead, GPU programmers need to think about data flow, where data is in GPU memory. As a rule of thumb, the slowest part of any computation is communication – specifically communication between the CPU and GPU, but also between different memory banks within the GPU, itself. This has a large number of implications that we will discuss in later chapters.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Even so, the transfer time of data for a relatively small array (like this one) should still be around a millisecond or two. My guess is that most users felt a significant delay of about a second or two when they created their first array. As a quick test, try to do the same command again (ArrayType(a)). This time, it should be really fast. The truth is that there is another, more important reason why the first array took so long to build. Let's talk about...","category":"page"},{"location":"content/abstractions/#Expected-performance-from-Julia","page":"All the Ways to GPU","title":"Expected performance from Julia","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"It's time to be upfront about one of the core weaknesses of Julia. At this stage, there are probably two distinct groups of people:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Those that are new to GPU programming. These people are probably scratching their head at all the new, unnecessary packages. After all, they just want to use their GPU! Why do they need to think so deeply about their hardware?\nThose who have attempted GPU programming before. These people are probably amazed at how easy the installation was. Julia just did everything for us in a way that seemed like magic!","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"There is a little truth to both of these claims. Yes, Julia does a lot of the heavy lifting for the user. And yes, there is still a lot of jank we are trying to get rid of.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"But there's another (potentially ill-formed) thought that might be lurking in the back of your mind, \"If all these Julia packages are just wrappers to C, why not use C instead? Won't we get a performance penalty for using Julia here?\"","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"That's a very good question, and it's difficult to fully explain. Long story short, Julia boils down to the same lower-level representation as C (if you are using the clang compiler), so it should be equivalently fast. It can also call C code without any performance penalty, so the wrappers to C should be equivalently fast. That said, we do need to draw a thin line in the sand here. In the case of GPU computing, we are not comparing ourselves to C, but CUDA (or Metal, AMD, etc). The lower-level representation of GPU languages are all slightly different than that of C. This means that in the case of GPU computing, we are actually asking Julia to do a lot. It has to dynamically determine our hardware, compile the Julia code into some intermediate representation, then spit out even lower level code that is distinct for each hardware vendor, all while maintaining the features that make Julia easy to use for beginners.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"When we put it all together, the compilation time for the JuliaGPU ecosystem can sometimes be much higher than for many other GPU languages. To be clear, we usually call compilation \"precompilation\" in Julia because the translation happens dynamically (immediately after Julia can statically know what all the types are when the user runs their code). Let's try to quantify our precompilation cost a bit by re-running the code with the @time macro:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> a = zeros(10,10);\n\njulia> GPUBackend.@time ROCArray(a);\n\njulia> GPUBackend.@time ROCArray(a)","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"For me, this looks like:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> a = zeros(10,10);\n\njulia> AMDGPU.@time ROCArray(a);\n  1.676601 seconds (7.35 M allocations: 508.234 MiB, 14.36% gc time, 85.91% comp\nilation time)\n\njulia> AMDGPU.@time ROCArray(a);\n  0.000370 seconds (12 allocations: 368 bytes)","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"The second run was literally 4,500 times faster! It's important to also look at the information in parentheses. The first run had 7.35 million allocations and spent 85% of it's time precompiling. The other roughly 15% of time was spent on garbage collection (cleaning up unnecessarily allocated memory). The second run had 12 allocations and no time at all on garbage collection or precompilation. It was also less than a millisecond.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"It is really important to keep in mind that Julia can (and should) get comparable performance to C in most cases, but we need to give it a second to precompile everything first. Even though many people in the Julia community are working on decreasing precompilation time, it is unlikely that this will go away entirely any time soon. If your specific GPU project requires fast recompilation regularly (which is the case for some graphics workflows), then you might need to take the lessons from this book and translate them into another language in the future.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"That said, I truly believe that Julia provides the most flexible ecosystem for most GPU workflows and should be a great starting language for any GPU project. In particular, it is the only language that provides so many different abstractions for doing GPU computation. Speaking of which, it's time to talk about them in detail.","category":"page"},{"location":"content/abstractions/#I-have-a-GPU-array.-Now-what?","page":"All the Ways to GPU","title":"I have a GPU array. Now what?","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Well, there are a lot of things we can do, actually, but let's start with the basics: indexing. Indexing is the act of accessing array memory one element (index) at a time. On the CPU, you might create an array, a, and get the first index with a[1]. It might be reasonable to assume that similar logic would work on the GPU, so let's try it:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> using GPUBackend\n\njulia> a = ones(10,10);\n\njulia> b = ArrayType(a);\n\njulia> a[1]\n1.0\n\njulia> b[1];\nERROR: Scalar indexing is disallowed.\nInvocation of getindex resulted in scalar indexing of a GPU array.\nThis is typically caused by calling an iterating implementation of a method.\nSuch implementations *do not* execute on the GPU, but very slowly on the CPU,\nand therefore should be avoided.\n\nIf you want to allow scalar iteration, use `allowscalar` or `@allowscalar`\nto enable scalar iteration globally or for the operations in question.\nStacktrace:\n\n...\n","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"As a reminder, GPUBackend and ArrayType depends on your hardware and can be found in the installation section.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"But what's the deal? Why can't I access elements of my GPU array? What does \"scalar indexing\" even mean?","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Simply put, scalar indexing is the act of accessing an array one element at a time, for example a[1], a[2], or a[i], where i is some integer value. As to why this is not allowed on the GPU, well... there are a bunch of factors all working against each other to make scalar indexing difficult. Remember, GPU memory is not \"on the CPU.\" When we run a[1], we are asking Julia to display that data in the REPL, but we can't do that without first transferring it to the motherboard RAM. With this scalar indexing error, Julia is asking us to be doubly sure that this is, in fact, what we want to do because (again) communication is slow. If we are absolutely sure that we want to display the first element of b, then it is best to be more explicit and first transfer the data back to the CPU with something like Array(b)[1], where Array(b) will transfer the data, and the [1] at the end will access the first element of the newly created CPU-based array.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"It's also important to remember that GPUs are intended to do a lot of things in parallel. This power is lost completely if we ask Julia to deal with only a single element at a time. Simply put, if users are using the GPU one index at a time, it's going to be really, really slow, so we need to do what we can to discourage that behaviour whenever possible.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"tip: But what if I *really* need scalar indexing\nKeep in mind that if you really need to access a single element of a GPU array and do not want to transfer the data to the CPU first, you can do it by first setting the allowscalar flag true (and then turning it off again afterwards):julia> GPUBackend.allowscalar(true)\n┌ Warning: It's not recommended to use allowscalar([true]) to allow scalar indexing.\n│ Instead, use `allowscalar() do end` or `@allowscalar` to denote exactly which operations can use scalar operations.\n└ @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:188\n\njulia> b[1]\n1.0\n\njulia> GPUBackend.allowscalar(false)\nYou can also wrap the necessary code in a do block, like so:GPUBackend.allowscalar() do\n    b[1]\nend\nOr use the provided macroGPUBackend.@allowscalar b[1]","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"So now that we've shaken everyone up a little bit by talking about something that is simultaneously trivial on CPUs and next to impossible on GPUs, let's talk about things we can actually do with our GPU array.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"In the next few sections, I will be discussing three different abstractions that are commonly used for GPU programming:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Broadcasting: the act of applying the same command to every element in an array.\nGPU functions (called kernels): the act of writing a specific function that gives instructions to each GPU core\nLoop vectorization: the act of transforming a for or while loop for GPU execution.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Before going further, it's worth noting that these abstractions are not available for all languages. For example, CUDA and OpenCL focus almost exclusively on user-defined GPU functions. SyCL and Kokkos focus on loop vectorization. Julia is unique in that all three of these major abstractions are deeply ingrained into the ecosystem as a whole and play very nicely not only with each other, but the broader Julia ecosystem.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"If you are planning on rewriting all the code in this book with another language, it might be a good idea to first jump to the abstraction that works well in the language you have chosen and then come back to the other sections as needed. For now, I intend to cover things in the order that feels most intuitive for GPU computation in Julia, starting with...","category":"page"},{"location":"content/abstractions/#Broadcasting","page":"All the Ways to GPU","title":"Broadcasting","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Ok. I get it. Most programmers have probably never used broadcasting. Many have probably never heard of it before now. Before using Julia, I certainly hadn't. So let's start at the start.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"To reiterate, broadcasting is the act of applying the same command (broadcasting in the colloquial sense) to every element in an array. Though accessing individual elements of a GPU array is a little complicated, applying the same operation to all elements of an array is surprisingly easy – in fact, it's perfect for the GPU!","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"So let's look at some basic syntax on the CPU first:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> a = zeros(10)\n10-element Vector{Float64}:\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n\njulia> a .= 1\n10-element Vector{Float64}:\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"In Julia, the . before some command indicates to the compiler that the user would like to broadcast the command to all elements of an array. So, these lines:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Created an array (Vector) of ten zeros, called a.\nBroadcasted the = 1 command to each element of the array, indicated with .= 1","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Now for some Julia magic: as long as you are can write your GPU code as broadcasted operations, it should be possible to execute that code in parallel on the GPU. For example, the following will also work:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> using GPUBackend\n\njulia> a = GPUBackend.zeros(10);\n\njulia> a .+= 1\n10-element ArrayType{Float32, 1, ...}:\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"And there you have it! You've just executed your first function on the GPU. Note that in this case, we switched things up a bit and used the .+= command instead of .=. This simply means that we added 1 to every element (the += operation) instead of setting every element equal to (=) 1. That said, we probably want to do things way more complicated than just adding one to every element of an array, so let's look at a few quick examples of broadcasting in practice.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"tip: What's up with the semicolon (`;`)?\nIn the Julia REPL, you can add a semicolon (;) to the end of a line if you do not want to show the output immediately. I'll be using this throughout the book to make the text a little more clear to read.","category":"page"},{"location":"content/abstractions/#Setting-every-odd-element-to-1","page":"All the Ways to GPU","title":"Setting every odd element to 1","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"We just added one to every element. What if we want to do something similar, but for every odd element? To do this, we need to define a custom range for accessing our Julia array. For example, if we want access only the first five elements of an array, we might use the range 1:5. If we want to choose every other element, then we would go in steps of two, so 1:2:5. Putting this together, if we want to set every odd element of an array to 1, we might do...","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> a = zeros(10);\n\njulia> a[1:2:10] .= 1;\n\njulia> a\n10-element Vector{Float64}:\n 1.0\n 0.0\n 1.0\n 0.0\n 1.0\n 0.0\n 1.0\n 0.0\n 1.0\n 0.0\n","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"And that's that. This was just a simple way of showing that any mathematical operation can be broadcasted, even if that operation is just assigning values.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Now for a few quick exercises to make sure we understand everything:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"todo: Problem 1: Do it on the GPU\nDo what we just did on your GPU backend. In other words, change the array type of a to your ArrayType and add one to every other element.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"todo: Problem 2: Subtract 1 from every even element\nCreate some broadcast operation that will subtract one from every even element.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"todo: Problem 3: Square each element of the array\nFor context, x^y is the math operator in Julia to \"raise some number (x) to the power of some other number (y). So the squaring operator in Julia for a single value would look like x ^= 2.Now broadcast that operation to your entire array.","category":"page"},{"location":"content/abstractions/#What's-the-difference-between-indexing-and-broadcasting?","page":"All the Ways to GPU","title":"What's the difference between indexing and broadcasting?","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Right. Good question.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"We just had two sections back-to-back with seemingly contradictory claims:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"It's not a good idea to grab individual indices of a GPU array.\nIt's a great idea to grab multiple indices at once.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"For many users, it might not be clear what the distinction is here. After all, what is the difference between a[1] and a[1:5]? Why is the latter so fundamentally different in Julia?","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"It is actually difficult to answer this question without digging in to the Julia programming language, itself (and the base/broadcast.jl file), but the simplest explanation is that the . before any operation signifies that the user would like to call the Julia map function, which distributes a function across elements of an array. For the Julia GPU ecosystem (in the GPUArrays.jl package), any broadcasted operation will actually create a specific GPU function for the map.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Simply put: if you are just trying to access a single element of a GPU array, we can not easily transform that into a GPU function that works in parallel on your hardware. If you are trying to do something with a bunch of elements, then it is easy(ish) to do so.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"And if you are wondering, yes. This does mean that you can get around the scalar indexing warning by using a range with only a single element, like:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> a = zeros(5):\n\njulia> b = ROCArray(a):\n\njulia> b[1:1]\n1-element ROCArray{Float64, 1, AMDGPU.Runtime.Mem.HIPBuffer}:\n 0.0","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Please don't abuse this too much.","category":"page"},{"location":"content/abstractions/#Vector-addition","page":"All the Ways to GPU","title":"Vector addition","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"When it comes to GPU computation, there is a single problem that every single person does to make sure their code is working as intended. It is so common, that the problem is often called the \"'Hello World!' of GPU computation. That problem is vector addition, the act of adding two vectors (lists of numbers) together. Let's do it with broadcasting.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> a = rand(10)\n10-element Vector{Float64}:\n 0.3446361752270596\n 0.6044872863666282\n 0.8081681226442919\n 0.6586667828785924\n 0.23172116207667204\n 0.08632001843030668\n 0.09675977506693823\n 0.6771842850312151\n 0.019671351328815923\n 0.7149572102336769\n\njulia> b = rand(10)\n10-element Vector{Float64}:\n 0.30677966842793747\n 0.27954729235962206\n 0.37278805220786826\n 0.7667780614002805\n 0.9295691111986113\n 0.6457830807742259\n 0.4943043624323966\n 0.8731592407550742\n 0.3415622970290325\n 0.32403477239711587\n\njulia> c = a .+ b\n10-element Vector{Float64}:\n 0.651415843654997\n 0.8840345787262502\n 1.1809561748521602\n 1.4254448442788727\n 1.1612902732752834\n 0.7321030992045325\n 0.5910641374993348\n 1.5503435257862894\n 0.36123364835784844\n 1.0389919826307927","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"So there's a lot to unpack here. Firstly, broadcasting can work in general on the right-hand side of any math equation (here shown with the .+ between a and b).. Secondly, rand(...) works the same way as zeros(...) or ones(...). Right now that might seem trivial, but random numbers are actually a little hard to do on GPUs, so we'll talk about that in a little more depth later. Thirdly, it's important to note that a and b must be the same size for this to work, so make sure that's true before broadcasting operations to more than one array.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"But there's a more subtle point here that many people might have missed, and it has to do with the third command, c = a .+ b. Simply put, c did not exist before running the command! This means that we have created a new array for the sole purpose of outputting the results of  a .+ b.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Though this might not seem particularly noteworthy on the CPU, it actually has large implications for the GPU. Remember that the slowest part of most computation is memory management, and here, we have allocated space for and assigned the values to a random array without even considering the consequences to performance! Allocation takes time! If at all possible, we want to minimize the number of times we create new arrays.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"So how might we rewrite things so that we don't unnecessarily allocate c? Well, the simplest solution is to allocate it at the same time as a and b and then use .= instead of =:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> a = rand(10);\n\njulia> b = rand(10);\n\njulia> c = similar(a);\n\njulia> c .= a .+ b","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Here, we use similar(a), which will create an array that is the same size, shape, and type as a, which should (hopefully) also be the same size, shape, and type as b. The data in c from similar will be just whatever junk was in memory at the time and won't necessarily be all zeros or anything. That shouldn't matter because c is used exclusively for output, so there's no reason to invoke rand(...) if we don't need it.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"There are actually distinct terms to distinguish between the two different types of computation we did:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"In Place computation is when all operations act on already existing data. In this case, the .= command broadcasts c[i] = a[i] + b[i] to all elements of the array, assuming a, b, and c already exist.\nOut of Place computation is when some operations create new data. In this case, the = sign assigns the output of a .+ b to a new array, called c.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"So c = a .+ b was out of place, while c .= a .+ b was in place. It's important to keep this in mind for later. Remember that data flow really matters with GPU computation, so it's doubly important to make sure you know where your data lives.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"A quick note. I would like to believe that every single Julia programmer has been tripped up by the difference between = and .=. I certainly have torn my own hair out late in the evening, trying to figure out why the performance of my code is so slow, only to realize I forgot a single ., which meant that I was creating a bunch of new arrays instead of writing to pre-existing arrays. This type of stuff happens to the best of us, which is why I am pointing it out now while you are young and impressionable. Julia syntax sometimes looks sleek, but there's a lot of power under-the-hood, so it is wise to take a second and make sure every line is actually doing what you want. ","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"I think that's it for now. On to some problems.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"todo: Problem 4: Try to add arrays of different sizes\n... and see the error message.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"todo: Problem 5: Do it on the GPU\nCreate three arrays, a, b, and c, all of type ArrayType for your specific GPU backend. Add a and b together and output them to c. You may create a, b, and c in any way you wish, but it might be more interesting to use ones(...) or rand(...) instead of zeros(...) because 0 + 0 = 0.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"todo: Problem 6: Add the first five elements of `a` to the last five elements of `b`\nCreate custom ranges so you can add one through five of a to five through ten of b. Remember that your output array (c), should be five elements this time!","category":"page"},{"location":"content/abstractions/#Broadcasting-generic-functions","page":"All the Ways to GPU","title":"Broadcasting generic functions","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Until now, we have been broadcasting pre-defined Julia functions (mainly math operations), but what if we wanted to broadcast our own (user-defined) functions? Well, let's do that. Let's say we wanted to find ten numbers between one and one-hundred. We might create a function that looks like this:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> f(x) = round(Int, x*100)","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"This would take some input (x), multiply it by one-hundred, and then round it to the nearest integer value (Int). So f(0.5) is 50. f(0.6542) is 65. And so on. Now let's broadcast that function to an array of random numbers:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> a = rand(10);\n\njulia> f.(a)\n10-element Vector{Int64}:\n 15\n 46\n 12\n 11\n 15\n 13\n 13\n 60\n 89\n 89\n","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Here, we've used the . operator to signify that we want the function broadcasted along all elements of the argument of f. Now let's create another function to do the vector addition from the previous section:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> g(a, b) = a + b\ng (generic function with 1 method)\n\njulia> a = rand(10);\n\njulia> b = rand(10);\n\njulia> c = similar(a);\n\njulia> c .= g.(a, b)\n10-element Vector{Float64}:\n 1.1339661653178916\n 0.9405969685936231\n 1.576334145965099\n 0.6608638707221182\n 1.2142578652057847\n 1.3606689325191113\n 0.7669673576476489\n 1.7838687185111035\n 1.370863980086035\n 1.5491853434156098\n","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"There are actually many different ways we could have done that. For example, we could have made g use c as an argument and then used g.(c, a, b). We could have also written our function using slightly different syntax in Julia, like:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"functon g(a, b)\n    return a + b\nend","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Feel free to explore different ways to do this if you want. In fact, I actively encourage you to do so.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"For now, let's wrap everything we've learned about broadcasting into a worked example that also shows off some of the power of GPU computing.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"note: Reviewer Notice\nI am thinking of replacing this upcoming section with something else that is potentially more interesting. Maybe one of the Diehard tests? I just couldn't think of one that works so well with broadcasting.","category":"page"},{"location":"content/abstractions/#A-simple-exercise:-\"Where-did-the-noise-go?\"","page":"All the Ways to GPU","title":"A simple exercise: \"Where did the noise go?\"","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Until now, I have avoided timing the majority of the our code because I wanted to make a point about GPU computation. Namely, if you are only working with a few elements at a time, the CPU will usually be faster. For example, here are the timing results for vector addition on my computer. First, let's do the CPU:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> a = rand(10);\n\njulia> b = rand(10);\n\njulia> c = similar(a);\n\njulia> @time c .= a .+ b\n  0.000003 seconds (1 allocation: 32 bytes)\n","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Now for the GPU:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> using AMDGPU\n\njulia> gpu_a = ROCArray(a);\n\njulia> gpu_b = ROCArray(b);\n\njulia> gpu_c = similar(gpu_a);\n\njulia> AMDGPU.@time gpu_c .= gpu_a + gpu_b;\n  0.000054 seconds (46 allocations: 2.500 KiB)\n","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Note that for both of these timings, I have shown only the results of the second run of the code to avoid precompilation overhead. Even so, it's clear the CPU is faster. How much faster?","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> 0.000054 / 0.000003\n18.0\n","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"18 times. It's 18 times faster to avoid the GPU entirely! Why? Well, we are doing operations that are a little too simple on arrays that are really, really small. I mean, the CPU took three microseconds. The GPU was fifty-four microseconds. Can we really draw any conclusions from such small numbers?","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"To really see some performance from the GPU, let's do something a little complicated. We are going to make an array of random numbers... disappear!","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"First, let's install the plotting package, Plots. Remember to enter Julia's package mode with ] (and then enter). Then:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"(@v1.10) pkg> add Plots","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Now press backspace to enter the Julia shell. We can now create a large matrix of random numbers and plot it:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> using Plots\n\njulia> a = rand(1920, 1080);\n\njulia> heatmap(a; clims = (0,1))","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"I have chosen to make the array 1920x1080 because that mirrors the resolution of a high-definition display. Also, we are using heatmap here (instead of plot) because we want a 2D image as output. I am also using color limits (clims) from zeros to one. This should create an image that looks like this:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"(Image: Initial Random Array)","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Now we are simply going to create a function that adds a random number to elements of a, so:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"f(x) = x + rand()","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Finally, we'll execute the command 1000 times in a loop and average the results","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> @time for i = 1:1000\n           a .= f.(a)\n       end\n  1.270488 seconds (1000 allocations: 15.625 KiB)\n\njulia> a ./= 1000;","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"It took about 1.5 seconds to do the computation and creates the following image (with heatmap(a; clims = (0,1)):","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"(Image: Initial Random Array)","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Wow! The color is gone from our plot as all the values have averaged to 0.5! What happened? Well, we just took 1000 random samples on each pixel and averaged them. Because rand(...) gives us a random number between 0 and 1, the final value for each pixel should be the average of 0 and 1, which is 0.5.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"note: About looping in Julia...\nLooping in Julia (and in many languages) generally has two modes: for and while. We have just seen the for loop in practice and is most often used over a range of a certain number of elements. For example:for i = 1:10\n    println(i)\nendWill set the value of i to be 1, execute the commant, then set the value of i to be 2 and execute the command again. After that, it will set the value of i to be 3 and execute the command again. It will continue this process until it reaches the end of the range provided (1:10), which is 10 in this case. This process is known as \"iteration\" and will be discussed in more detail later in this chapter when we talk about loop vectorization. For now, I'll mention that the for loops allows users to iterate through any container, including Arrays, but not GPUArrays due to the scalar iteration issue discussed earlier. So the following is also valid:julia> a = [1,3,5,7];\n\njulia> for i in a\n           println(i)\n       end\n1\n3\n5\n7The other common looping structure in Julia is the while loop, which continues executing the same command over and over until some condition is evaluated as false. For example:i = 1\nwhile i <= 10\n    println(i)\n    i += 1\nendThis code will also print 1 through 10 as above becaue when i evaluates as 11, the statement i <= 10 is evaluated as false, breaking the loop. We'll be showing off a bunch of tricks you can do with looping in Julia throughout this text, but it is worthwhile to take a second to introduce them to users who might not be familiar with the syntax.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Ok. I get it. It's not that impressive. There are some fun discussions we could have about testing how random random number generators truly are, but that would take a lot of time. If you are interested in that kind of stuff, I would recommend you look into Diehard tests. They are a fun suite of tests specifically for random number generation. For now, we'll move on to the real magic and run the same code on the GPU:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"julia> AMDGPU.@time for i = 1:1000\n           b .= f.(b)\n       end\n  0.001738 seconds (18.00 k allocations: 1.068 MiB)\n\njulia> b ./= 1000;","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Did you see that? 1.738 milliseconds. That's roughly 1000 times faster than our CPU implementation!","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Here we (finally) start to see a glimpse of the true power of GPU computing. On the one hand, we need to balance our complexity a bit. If the code is too complex, the CPU will do it better because each individual core is stronger. If there is not enough data (zeros(10)), again it's better to stick to the CPU. But when the GPU is in its element, it can really shine.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Now, don't expect every problem to be 1000 times faster on the GPU. I have specifically manufactured this toy problem to show off how fast it can be. In actual applications, developers typically see anywhere from 5-100 times improvement depending on the situation. Still, it's nice to know that we are doing all of this for a good reason: performance.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"todo: Problem 7: Do it on your machine\nI know some of you were tic-tac-typing along with me through the last exercise. Some were not. This problem is a gentle encouragement from me to you to make doubly sure you can do the previous example on your own machine with your own GPU.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"note: Reviewer Notice\nI need a few more good problems for this section. Or maybe not? I'll have a bunch more problems at the end and there's only so much you can do with broadcasting.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"I think it's time to take a second to discuss the limitations of broadcasting.","category":"page"},{"location":"content/abstractions/#Some-room-for-development","page":"All the Ways to GPU","title":"Some room for development","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"So here's a weird quirk of the Julia ecosystem. Something that might cause us to reconsider the speedup noted in the previous section. Even though broadcasted operations performed on a GPU array are done in parallel by default, the same is not true for traditional CPU Arrays. To be doubly clear, this will be executed in parallel:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"a = GPUBackend.ones(100)\na .+= a","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"but this will not:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"a = ones(100)\na .+= a","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"There are a lot of good reasons for why this is the case. Some of it comes down to engineering time. Some of it comes down to active research questions regarding the proper procedure to distribute generic operations in parallel. For the purposes of this book, none of that matters because we are talking about GPU execution, specifically.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Ultimately, this means that the comparison between the CPU and GPU made in the previous section might not have been entirely fair. We were not comparing parallel CPU to parallel GPU. Instead, we were comparing a single CPU core to the entire power of the GPU. If I were instead to use all the cores available on my machine (16), then we could expect to see an order of magnitude improvement on the previous result for the CPU. So instead of a 1000 times improvement, there might have been only 50 or so.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"All said, it's good to point out areas within the Julia language that are being worked on, but are not fully finished yet. In fact, there are a bunch of similar stories throughout the GPU ecosystem and I will try to point these out as they come up.","category":"page"},{"location":"content/abstractions/#Final-musings-on-broadcasting-for-GPU-computation","page":"All the Ways to GPU","title":"Final musings on broadcasting for GPU computation","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"When started working at MIT, I was excited to see what people were actually using the GPU ecosystem in Julia for. At the time, I came across an ocean simulation project with incredibly enthusiastic developers. It was fast and intuitive to use, and they highlighted the fact that it was fully functional on the GPU. Coming from a more traditional graphics background, I was shocked to find out that they had written their entire codebase solely using broadcasting operations and in-built Julia functions.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Upon further reflection, I realized I needed to check my own biases. Broadcasting provides a hardware-agnostic method for performing almost any mathematical operation! If a user is exclusively crunching numbers, then there is almost no better abstraction than writing down the math and adding a few .s here and there.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Even so, after a few years, the ocean team sought even better performance and eventually rewrote their code using GPU-exclusive functions (kernels), which will be introduced in the following section. Simply put, broadcasting is an absolutely excellent way to get started with GPU computation in Julia. It's an intuitive abstraction and will get you most of the performance you need from the GPU.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"But there's a reason this work is called the GPU Kernel Handbook. When you need true flexibility or performance, there is no better abstraction than writing functions specifically for the GPU.","category":"page"},{"location":"content/abstractions/#GPU-Functions:-Kernels","page":"All the Ways to GPU","title":"GPU Functions: Kernels","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"To recap, we have already introduced a language abstraction, known as broadcasting, that can be used out-of-the box in Julia for great GPU performance in most cases. We also walked through a simple example that used broadcasting to show the power of GPU computing with a 1000 times speed-up (on my hardware, at least) when compared to single-core CPU execution. This means that we should have some vague notion of how GPU execution works and what problems it's suited for, but now it's time to talk about the most common abstraction used for GPU programming: kernels.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"In GPU programming, a kernel is a function specifically written to be run on the GPU for some computational task. In principle, the only difference between a kernel and a regular function is that kernels are meant to run in parallel on each core. This means that every core should run the same, exact function at the same time, but there are a few caveats to mention. For one, keep in mind that a lot of GPU computation will require more units of computation than there are cores. For example, a high-definition image might have 1920 x 1080 pixels in it. If the coloring or shading of each pixel is handled by a single core, then we would need 2,073,600 cores to do the computation. Unfortunately, the fastest GPUs in the world only have around 10,000 cores available. So what do we do? Well, we don't really worry about that and instead let a scheduler stage the computation to happen in groups of cores in parallel.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Keep in mind that kernels are abstractions. They are purposefully hiding information from users to make programming easier. In this case, users shouldn't need to think about the exact mechanics of scheduling on the GPU and can instead focus on writing down the specific computation that each core should perform. That said, programmers (like myself) are sometimes pedantic and will often distinguish terms a bit here. Instead of talking about \"cores,\" which are pieces of hardware, we often talk about \"work items\" (or \"threads\" for CUDA), which are abstract representations of cores to later be scheduled on to cores. To be clear, every work item corresponds to some core performing that computation, but we are letting the compiler choose which core each work item will run on. In this way, we don't need to worry about specifics of GPU hardware and can instead program them from a much more general perspective.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"I think that's enough background info for now. In fact, it might be too much. Let's get to writing some kernels. To be clear, each GPU backend (CUDA, AMD, Metal, oneAPI) all provide their own kernel interfaces that work in Julia, but we will be using KernelAbstractions for this work, so we need to start by adding that package. Start by pressing ] and then enter to enter package mode. Then:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"(@v1.10) pkg> add KernelAbstractions","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Press enter. Install the library. Now we are ready to write our first GPU kernel.","category":"page"},{"location":"content/abstractions/#Vector-addition,-but-this-time-with-kernels.","page":"All the Ways to GPU","title":"Vector addition, but this time with kernels.","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Like I said before, vector addition is the \"Hello World!\" of GPU programming. It's one of the simplest units of computation that can be done on the GPU to test functionality. So, let's start by writing down a function that might add two elements of separate arrays together:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"function add!(c, a, b, idx)\n    c[idx] = a[idx] + b[idx]\nend","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"This function will take in three arrays (a, b, and c) and add the idx index of a and b to the idx index of  c. So add!(c, a, b, 1) would be the same as c[1] = a[1] + b[1]. To be honest, it's a bit of a weird formulation, but bear with me. From here, it's relatively easy to transform the code into a GPU kernel that works on every work item (core). We just need to:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Add using KernelAbstractions to the start of our script.\nAdd the @kernel macro to the start of our function.\nMove the idx definition to inside the function with something like idx = @index(Global), where Global signifies that we are pulling from all globally available threads.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"tip: What's the exclamation point (`!`) for?\nIn programming, there is a concept known as \"mutation\" that indicates an in-place change to the values of an array or structure. For example, setting a[1] = 5 mutates a. It changes a single element, but a is still the same size and shape it was before. In Julia, functions can also mutate data, such as in add!(c, a, b, idx) above. In these cases, it is good practice (though not a requirement) to notate the function with an exclamation point (!). It's also common to put the array(s) that will be mutated at the start of the argument list, which is why we set the order of add! to be c, a, b instead of a, b, c. At the end of the day, these are just small notational changes to help other people understand how your code works. It's up to you whether they make sense in your, specific context.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"using KernelAbstractions\n\n@kernel function add!(c, a, b)\n    idx = @index(Global)\n    c[idx] = a[idx] + b[idx]\nend","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"And that's the whole function. Now we just need to run it. This is generally done in 3 steps:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Configure all the input variables. In this case, it would mean making sure that a, b, and c are all of the appropriate array type for running the code on the GPU or in parallel on the CPU with the generic Array type.\nConfigure the kernel. This is done by first getting the right backend (for example, AMD, NVIDIA, Metal, etc), and then running the kernel with that backend as a function argument, so kernel = add!(get_backend(a)).\nRun the kernel with the appropriate arguments, so kernel(c, a, b, ndrange = length(a)). Here ndrange is an n-dimensional range of values to index over. In this case, as long as a, b, and c are all the same length, we can set the range to be the length(...) of any of the three.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Putting all of that together:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"a = ArrayType(rand(10))\nb = ArrayType(rand(10))\nc = similar(a)\n\nbackend = get_backend(a)\nkernel = add!(backend)\nkernel(c, a, b; ndrange = length(a))","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"After running this, c should be a .+ b. Actually, now is a perfect time to test our results, so let's do that by comparing the results to broadcasting:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"using Test\n\n@test c == a .+ b\n","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Running this should return Test Passed into the REPL. And that's all there is to it. Your first GPU kernel.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Take a second to breath and pat yourself on the back a bit. At this point in time, you have taken a bold step into the world of GPU computing. There are a lot of specifics to talk about from here, but for many tasks, this level of GPU understanding is already enough to start seeing some benefits from the GPU. That said, there is still a lot left to do and many more pages in this book, so I do hope you keep reading to learn more.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"todo: Problem 8: Do it on your machine\nIn case you haven't done it already, it is important to do this exercise on your own machine to make sure you understand how everything is put together. Basically, add a and b and make sure the results match what you expected from the broadcasting results.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"todo: Problem 9: Set each array element equal to it's index\nCreate a simple kernel that sets every element of an array equal to it's index (idx = @index(Global) in the previous example)","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"todo: Problem 10: Create a sine wave\nCreate a simple kernel that creates a sine wave when plotting. Then pass it back to the CPU and plot it with plot(...) from the Plots package.Hint: You instead of setting each element of the array equal to it's index, set it to some value between 0 and 2pi and then pass that in to a sin function. In the end, it might look like this: `sin(idx / (2pi))`.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"todo: Problem 11: Add half of an array to another array\nCreate two arrays and add the first half of one to the second half of the other. This involves creating a custom ndrange that might be something like length(a)/2 where a is one of your arrays.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"note: Reviewer's Notice\nAgain, looking for more problems.","category":"page"},{"location":"content/abstractions/#A-discussion-on-loop-vectorization","page":"All the Ways to GPU","title":"A discussion on loop vectorization","text":"","category":"section"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"At this point in time, I have introduced two separate abstractions for GPU computing: broadcasting and kernels. I have discussed several core benefits of both, but acknowledge that neither one is common outside of specific circles. There is yet another abstraction commonly used for GPU programming. One that everyone knows (and many people love). They are one of the first things people learn how to do in any new programming language and are essential tools for almost any workflow. Yes, I'm talking about loops.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"On paper, loops look like perfect abstractions for parallel computing. After all, they iterate through a list. It should be entirely possible to distribute that work to multiple cores, so that (for instance) core 1 handles iteration 1 and core 4 handles iteration 4. In fact, this is precisely what loop vectorization is, and there are plenty of GPU libraries that use loop vectorization for various GPU backends.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"With all that said, I have personally never found them to be intuitive abstractions for parallel programming. I have always had trouble precisely explaining why this is the case, but let me try. Here is a parallel, CPU for loop in Julia:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Threads.@threads for i = 1:10\n    println(i)\nend","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Note that to use this loop, we need to launch Julia with a certain number of threads, such as julia -t 12 for 12 threads. After, all we need to do is add the @threads macro from the Threads package to the start of the loop. At a glance, it looks incredibly straightforward, but let's look at the output for single core and parallel execution:","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"single-core parallel\n1 2\n2 1\n3 10\n4 8\n5 5\n6 9\n7 3\n8 4\n9 7\n10 6","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"The single core results look great, but the parallel ones are all jumbled up! Why? Well because the single core loop executed iteratively while the parallel loop executed in parallel. This means that each println(i) statement was given to a different CPU core. If the core was slightly faster (as in core 2), it printed first. If the core was slightly slower (as in core 6), it printed last. If the core was somewhere in the middle, it printed out somewhere in the middle. For parallel loops, the output order is independent of the iterative count between 1 and 10.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"I remember when I saw this for the first time, I was surprised. In my mind, it shouldn't have mattered when the cores finished their operations. The for loop should have just output everything in the right order, regardless of when the computation was done! But upon further reflection, I realized my own perspective was naive.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"The fact is that Threads.@threads is fundamentally changing the loop into something completely different. We can't just slap that bad boy on anything. When we use Threads.@threads, we need to think about the ramifications of parallelism in the very same way we would think about writing complex kernels and distributing that work to the GPU. It's just now we also need to fight our own intuition on how these loops should function.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Another problem with looping is that many loops are inherently iterative and cannot be easily parallelized. Take timestepping, for example (the act of simulating motion, one small time step at a time). In this case, the first step (i = 1) must come before i = 2, which must come before i = 3, and so on. There is no issue with this when running code on a single core of a CPU, but let's face it: no one is currently writing code for a single-core CPU because such computers essentially don't exist. Nowadays, we really do care about parallelism. Threads.@threads (or similar approaches from other languages) feels a bandage solution to transform an iterative method into a parallel one which can be misleading for students and programmers.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"In addition, by relying on loops for parallelism, the code ends up being a large set of nested for loops, with one set of loops somewhere in the middle being parallel, while the rest remain iterative. It can quickly become a huge mess. While it is usually quite clear how to parallelize kernels, the choice of which loop to parallelize over is sometimes difficult for beginner programmers. At least in my experience, I have found that codebases using parallel loops end up looking just as messy, if not messier, than code using kernel-based approaches. On the other hand, for programmers that know what they are doing, loop-based abstractions can still be quite helpful – especially for code that already exists and would be a pain to rewrite. There are also GPU languages (like Kokkos and SyCL) that use parallel loops by default.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Unfortunately, for all the reasons mentioned here, there are is not strong library support for loop vectorization on the GPU in Julia, though there have been many attempts. If you absolutely need a loop-based abstraction for parallel GPU programming in Julia, I would recommend looking into GPUifyLoops.jl, Floops.jl, or JACC.jl. By the time you are reading this, there might be another solution that exists as well.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"To wrap up my thoughts on looping as a useful abstraction for GPU computing, I'll say this. The most popular language for GPGPU today is CUDA, and it uses kernels exclusively. I love broadcasting, but acknowledge it is essentially never used outside of niche applications. A lot of computer scientists still believe loops are the answer. But if we are looking at the numbers, it's incredibly clear that kernels have won the GPU abstraction wars, and for good reason. Kernels are more flexible than loops and are often more straightforward to write and integrate into a pre-existing software project. It feels like loop vectorization exists as a olive branch to traditional CPU programmers who are unwilling to change their code to better reflect the world around them.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"Ok. I think this is a good place to stop rambling. We covered all the basics necessary for the rest of this text. In the following chapters, we will begin to dive deeply into all the different things we can do with GPU kernels, starting with the most trivial stumbling block: summation.","category":"page"},{"location":"content/abstractions/","page":"All the Ways to GPU","title":"All the Ways to GPU","text":"note: Reviewer's Notice\nAgain looking for general problem sets for readers to go through. I'll be fleshing this out later as the future directions become more clear.","category":"page"},{"location":"#What's-Going-On?","page":"Welcome","title":"What's Going On?","text":"","category":"section"},{"location":"","page":"Welcome","title":"Welcome","text":"When I started my PhD in 2014, it was fairly uncommon for programmers to use their Graphics Processing Unit (GPU) for any computation beyond what was necessary for gaming or some graphical applications. The world has changed since then. Nowadays, it feels like the GPU is the most important piece of hardware on any computational device (supercomputers, desktops, phones, etc). Computer Generated Imagery (CGI) for movies and games have become almost photorealistic, and all of the necessary computation happens on the GPU. The fastest supercomputers in the world run GPUs. Machine learning models are trained using GPUs. Everyone needs the GPU for something.","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"At the same time, there are very few good learning resources available to teach beginner programmers how to properly use their hardware. So that's what this book is. It is a gentle introduction to most of the programming concepts necessary to understand GPU computing through meaningful, real-world applications.","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"All of the content on this site was created by James Schloss (Leios). The code is released under the MIT license, which means you can use it for virtually any purpose as long as you attribute me and you let everyone know that my code is freely available under the MIT license for use. The text is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA). This means that you are free to read, copy, modify, and remix any of the text here with a few key restrictions. Namely, the new (derivative) work:","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"Cannot make money.\nMust attribute me (James Schloss or Leios).\nMust be available for free with the same Creative Commons license. In other words, derivatives of derivatives of this work cannot make money and also must attribute me (and any additional authors).","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"if this book is useful for you, please consider purchasing it when it is officially released. If you would like to purchase the book, please let me know here. Otherwise, please let me know if there are any typos, errors, or jank that you find along the way.","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"Thanks for reading and I hope the book helps you in some way!","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"Welcome to the world of General Purpose Graphics Processing Unit (GPGPU) computation.","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"Dr. James Schloss (Leios)","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"(Image: CC BY NC SA)","category":"page"}]
}
